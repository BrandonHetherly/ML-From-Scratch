### Linear Regression
- temp

### Logistic Regression
- I use gradient descent for optimization
- Accuracy scores differ between models:
  - Sklearns model does not use gradient descent
  - Sklearn defaults to L2 regularization (Ridge), which is not present in the class (I will add regularization in the future)

### KNN
- temp

### Naive Bayes
- Assumes all features are mutually independent
- Assumes all features follow a Gaussian distribution

### Perceptron
- It is one unit of a Artificial neural Network (ANN)
  - Simulates the behavior of a single neuron
- It is a form of supervised learning and the output is binary 
#### Steps 
1) The 'cell' takes inputs and weights
2) Multiply the inputs and weights and sum to create a weighted sum
3) The weighted sum is fed into a activation function which returns the models output 
